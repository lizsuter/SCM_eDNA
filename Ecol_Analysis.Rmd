---
title: "Processing Results from DADA2 to make plots, do some statistics"
author: "Liz Suter"
date: "May 21, 2021"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

[Link](https://lizsuter.github.io/files/Ecol_analysis.nb.html) to notebook  

[Link](https://github.com/lizsuter/SCM_eDNA) to github repo.


<br/>

# Table of Contents
- [Load packages](#load-packages)
- [Import and prepare the data from eDNA](#import-and-prepare-the-data-from-edna)
  - [Import metadata](#import-metadata)
  - [Import DADA2 results](#import-dada2-results)
  - [Make phyloseq object](#make-phyloseq-object)
- [QC and filtering eDNA dataset](#qc-and-filtering-edna-dataset)
  - [Rarefaction curves](#rarefaction-curves)
  - [Filtering](#filtering)
  - [Check sequencing effort](#check-sequencing-effort)
- [Abundance plots eDNA](#abundance-plots-edna)
  - [Abundance at family level](#abundance-at-family-level)
  - [Bubble plots](#bubble-plots)
    - [Bubble plot without Elasmobranchs](#bubble-plot-without-elasmobranchs)
- [Import and prepare the data from trawls](#import-and-prepare-the-data-from-trawls)
  - [Import Trawl Count Data](#import-trawl-count-data)
- [Abundance plots Trawls](#abundance-plots-trawls)
  - [Bubble plots of Counts](#bubble-plots-of-counts)
  - [Bubble plots of CPUE](#bubble-plots-of-cpue)
- [Compare Trawl and eDNA](#compare-trawl-and-edna)
 - [Prepare the data](#prepare-the-data)
 - [Species Richness](#species-richness)
 - [Species tally across whole study](#species-tally-across-whole-study)
- [Exploratory Analyses](#exploratory-analyses)
  - [Ordinations on eDNA](#ordinations-on-edna)
      - [PCA](#pca)
      - [PCoA Jaccard](#pcoa-jaccard)
      - [PCoA Bray Curtis](#pcoa-bray-curtis)
      - [NMDS Aitchison](#nmds-aitchison)
      - [NMDS Jacaard](#nmds-jacaard)
      - [NMDS Bray Curtis](#nmds-bray-curtis)
      - [eDNA Ordinations Summary](#edna-ordinations-summary)
  - [PCoA with Environmental Variables](#pcoa-with-environmental-variables)
  - [Ordinations on CPUE](#ordinations-on-cpue)
      
<br/>



# Load packages

```{r}
library(tidyverse)
library(readxl)
library(phyloseq)
library(Biostrings)
#library(phangorn)
library(readr)
library(seqinr)
library(decontam)
library(ape)
library(vegan)
#library(philr)
library(RColorBrewer)
library(microbiome)
#library(DESeq2)
library(compositions);
library(cowplot)
library(plotly)
library(htmlwidgets)
library(withr)
library(lubridate)
```

#  Import and prepare the data from eDNA 

## Import metadata
```{r}
metadata <- read_csv("sample_data.csv")
```


## Import DADA2 results
Import count table and taxonomy file. I slightly modified otutable.csv in Excel to otutable_mod.csv to remove the quotes around seq names and put NA placehoder as first col name (which was above row names)
```{r}
# Import Count table. Skip first row of tsv file, which is just some text
count_table <- read_table2("results/otutable_mod.csv")
colnames(count_table)[1] <- "SampleID"

# Import taxonomy of ASVs
taxonomy <- read_csv(file="results/tax_sequences_blast_taxonomy.csv")
# remove first col of sequential numbers
taxonomy[,1] <- NULL
# filter out sequences with low PID (recommended by Sara)
taxonomy <- filter(taxonomy, PID > 92)

# remove BLAST metadata and just retain taxonomy (necessary for further processing below)
drop.cols <- c(colnames(taxonomy)[2:9],'RefSeq_Tax_ID_1')
taxonomy <-  select(taxonomy, -one_of(drop.cols))


# And import the Common names, as curated by Sara. Join to taxonomy
commonnames <- read_excel("Trawls MASTER 2020 _mod_ES.xlsx",7)
commonnames

taxonomy <- left_join(taxonomy, commonnames, by = "ASV_ID")
taxonomy

```
Filtering removed seqs 110, 332 (Gobiosoma ginsburgi and Belone belone)
*Note for Sara* should we consider setting this at 97% which is more robust and still leaves 334 unique ASVs (rather than 379 with the 92% cutoff in the settings above)

Preview datasets
```{r}
count_table
taxonomy
metadata
```




## Make phyloseq object

I want to use the phyloseq package for some plotting/ statistics, which first requires making phyloseq objects out of each of input data tables- 

```{r}
count_table_matrix <- as.matrix(count_table[,2:392]) # convert count table to matrix, leaving out character column of sample ID
rownames(count_table_matrix) <- count_table$SampleID # add back in Sample IDs as row names
ASV	=	otu_table(count_table_matrix, taxa_are_rows =  FALSE)

taxonomy_matrix <- as.matrix(taxonomy[,2:9])
rownames(taxonomy_matrix) <- taxonomy$ASV_ID 
TAX	=	tax_table(taxonomy_matrix)

# select only the metada rows with eDNA samples
metadata_edna <- metadata %>% filter(!is.na(SampleID))

META	=	sample_data(data.frame(metadata_edna, row.names = metadata_edna$`SampleID`))
```


First check that the inputs are in compatible formats by checking for ASV names with the phyloseq function, taxa_names
```{r}
head(taxa_names(TAX))
head(taxa_names(ASV))
```

And check sample names were also detected
```{r}
# Modify taxa names in ASV, which are formatted with the sample ID, underscor, fastq ID. Don't need this fastq ID anymore and want it to match the sample names from metadata
sample_names(ASV) <-  sample_names(ASV) %>%
  str_replace_all(pattern = "_S[:digit:]+",replacement = "")


head(sample_names(ASV))
head(sample_names(META))
```

And make the phyloseq object
```{r}
ps <- phyloseq(ASV,	TAX,	META)
```



# QC and filtering eDNA dataset

## Rarefaction curves

```{r}
rarecurve(otu_table(ps), step=50, cex=0.5)

# save as .eps
setEPS()
postscript("Figures/rarefaction.eps")
rarecurve(otu_table(ps), step=50, cex=0.5)
dev.off()
```
Most samples look like they were sampled to completion. Be weary of T3S11, T1S2, and maybe T4S5


## Filtering

Check some features of the phyloseq object
```{r}
rank_names(ps)

unique(tax_table(ps)[, "superkingdom"])
unique(tax_table(ps)[, "phylum"])
unique(tax_table(ps)[, "class"])
```

There are some ASVs with `NA` as superkingdom, phylum, or class annotation- delete these. 

```{r}
ps <- subset_taxa(ps, !is.na(superkingdom) & !is.na(phylum) & !is.na(class))

unique(tax_table(ps)[, "superkingdom"])
unique(tax_table(ps)[, "phylum"])
unique(tax_table(ps)[, "class"])
nrow(tax_table(ps)) # number of ASVs left
```
378 ASVs still remain...


Also check class Mammalia, to see if they are contamination or real:
```{r}
tax_table(subset_taxa(ps, class == 'Mammalia'))
```
These are human, wild boar, cat (ahem...cat lady), and cattle. All are contamination so delete all Mammalia

```{r}
ps <- subset_taxa(ps, !class == 'Mammalia')
unique(tax_table(ps)[, "class"])
```

Next check the "Insecta" entries
```{r}
tax_table(subset_taxa(ps, class == 'Insecta'))
```

The onlly Insecta is Linepithema humile, which are ants so delete these too..
```{r}
ps <- subset_taxa(ps, !class == 'Insecta')
unique(tax_table(ps)[, "class"])
```


## Check sequencing effort

Check overall how many ASVs there are per sample

```{r}
# First aglomerate the ASVs at the phylum level using the phyloseq function, tax_glom
superkingdomGlommed = tax_glom(ps, "superkingdom")

# and plot
plot_bar(superkingdomGlommed, x = "Sample")

ggsave(filename = "Figures/seqdepth.eps", plot = plot_bar(superkingdomGlommed, x = "Sample"), units = c("in"), width = 9, height = 6, dpi = 300, )# and save

```
Total sequences reveals certain samples had very low sequencing effort: T1S7, T1S8, T3S11, and, not as bad, T1S2 and T4S5



The rarefaction analysis also showed T1S2 and T4S5 samples were likely not sequenced to completion. Therefore remove these 5 samples from analysis
```{r}
ps <- subset_samples(ps, !SampleID == "T1S7" & !SampleID == "T1S8" & !SampleID == "T3S11" & !SampleID == "T1S2" & !SampleID == "T4S5")

ps
```

50 samples remaining with 368 ASVs


Remove Pos Controls (all hits in positive controls are the same family- I assume this is expected)
```{r}
ps <- subset_samples(ps, !SampleID == "T1PosCon" & !SampleID == "T2PosCon" & !SampleID == "T3PosCon")
ps
```

47 samples remaining with 368 unique ASVs


And lastly, correct some taxonomy: **First* according to Sara, Engraulis encrasicolus (European anchovy) and Engraulis mordax should be Anchoa mitchilli (Bay anchovy):

```{r}
tax_table(ps) <- gsub(tax_table(ps), pattern = "Engraulis encrasicolus", replacement = "Anchoa mitchilli")  
tax_table(ps) <- gsub(tax_table(ps), pattern = "Engraulis mordax", replacement = "Anchoa mitchilli")  
```


**Second** the Fourhorn sculpin (Myoxocephalus quadricornis) is actually an Arctic species. This ASV has 100% PID and 100% query cover to Myoxocephalus quadricornis & Myoxocephalus scorpius (another Arctic species) and 99.4% PID, 100% query cover to Myoxocephalus aenaeus. This latter one is actually the regional species, so this is more likely to be the identity:
```{r}
tax_table(ps) <- gsub(tax_table(ps), pattern = "Myoxocephalus quadricornis", replacement = "Myoxocephalus aenaeus") 
tax_table(ps) <- gsub(tax_table(ps), pattern = "Fourhorn sculpin", replacement = "Grubby sculpin") 
```


**Third** Scomber japonicus, the chub mackerel, is only found in the Indo-Pacific. While this is a commercial product and could be here due to sewage, it is more likely the Scomber colias (Atlantic chub mackerel), which is found regionally (in the open ocean Atlantic). The blast hit to Scomber japonicus has PID of 100% and query cover of 100% while the similarity to Scomber colias 100% query cover/ 99.41% PID.

```{r}
tax_table(ps) <- gsub(tax_table(ps), pattern = "Scomber japonicus", replacement = "Scomber colias") 
tax_table(ps) <- gsub(tax_table(ps), pattern = "Chub mackerel", replacement = "Atlantic chub mackerel") 
```


```{r}
ps
```

47 samples remainwith 368 unique ASVs




# Abundance plots eDNA

For plotting, use *relative abundances* (# of ASV sequences/sum total sequences in sample), calculated easily using microbiome::transform

```{r}
ps_ra <- microbiome::transform(ps, transform = "compositional")
```

Export the relative abundance matrix so Sara can have it:
```{r}
# Extract abundance matrix from the phyloseq object
RelAbun_matrix = as(otu_table(ps_ra), "matrix")

# Coerce to data.frame
RelAbun_dataframe = as.data.frame(RelAbun_matrix)

# Export
write.csv(RelAbun_dataframe,"results/otutable_relabun.csv", row.names = TRUE)

```



## Abundance at family level
Then aglomerate the ASVs at the family level using the phyloseq function, tax_glom
```{r}
familyGlommed_RA = tax_glom(ps_ra, "family")
family_barplot <- plot_bar(familyGlommed_RA, x = "Sample", fill = "family")
family_barplot

```
**NOTES** for Sara

- There are some samples, (T1S3, T1S6, T2S11, T3S10, T3S4, T3S5, T3S9, T4S4, T4S7, T5S7) which are composed almost exclusively of 1 family. This might be fine, but I'm not used to seeing this with prokaroytic data. Just want to check with you



Agglomerate by species to see if I get the same 38 unique species Sara sees:

```{r}
speciesGlommed_RA = tax_glom(ps_ra, "CommonName")
speciesGlommed_RA
tax_table(speciesGlommed_RA)

```




## Bubble plots

Based on my previous [scripts](https://github.com/lizsuter/Cariaco_Euk) with Cariaco Eukaryotic data
```{r}
# convert ps object to dataframe using phyloseq's psmelt
species_df <- psmelt(speciesGlommed_RA)

# replace zeroes in the table with NA
species_df[species_df == 0] <- NA

# and remove rows with NAs in abundance  (this is so they don't appear as small dots in plot)
species_df <-  filter(species_df, !is.na(Abundance))
```



Plot by species, scientific name
```{r}
speciesbubbleplot_eDNA_sciname <- ggplot(species_df, aes(x = Station, y = fct_rev(species), color = Station)) + # the fancy stuff around y (species) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size = Abundance, fill = Station), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(0,.25,.5,.75,1), max_size = 6)+
  xlab("")+
  ylab("")+
  labs(size="Relative Abundance")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(Datecode~Bayside, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_eDNA_sciname
```



Plot by species common name
```{r}
speciesbubbleplot_eDNA_comname <- ggplot(species_df, aes(x = Station, y = fct_rev(CommonName), color = Station)) + # the fancy stuff around y (CommonName) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size = Abundance, fill = Station), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(0,.25,.5,.75,1), max_size = 6)+
  xlab("")+
  ylab("")+
  labs(size="Relative Abundance")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(Datecode~Bayside, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_eDNA_comname
```


Exportfigures
```{r}
ggsave(filename = "Figures/speciesbubbleplot_eDNA_sciname.eps", plot = speciesbubbleplot_eDNA_sciname, units = c("in"), width = 7, height = 12, dpi = 300)

ggsave(filename = "Figures/speciesbubbleplot_eDNA_comname.eps", plot = speciesbubbleplot_eDNA_comname, units = c("in"), width = 7, height = 12, dpi = 300)
```




### Bubble plot without Elasmobranchs
The above look good but they include two elasmobranchs, the dusky smooth-hound shark and cownose ray. While these are probably real, the MiFISH primers don't actually target the elasmobranchs, so we can't trust this assay to fairly represent these non-target species. Filter out and re-make the bubble plots:

```{r}
ps_no_elasmo <- subset_taxa(ps, !CommonName == 'Cownose ray')
ps_no_elasmo <- subset_taxa(ps_no_elasmo, !CommonName =='Dusky smooth-hound shark')

ps_ra_no_elasmo <- subset_taxa(ps_ra, !CommonName == 'Cownose ray')
ps_ra_no_elasmo <- subset_taxa(ps_ra_no_elasmo, !CommonName =='Dusky smooth-hound shark')

# and check
speciesGlommed_RA_no_elasmo = tax_glom(ps_ra_no_elasmo, "CommonName")
speciesGlommed_RA_no_elasmo
tax_table(speciesGlommed_RA_no_elasmo)
```

Remake bubble plots. First melt for tidyverse format

```{r}
# convert ps object to dataframe using phyloseq's psmelt
species_df_no_elasmo <- psmelt(speciesGlommed_RA_no_elasmo)

# replace zeroes in the table with NA
species_df_no_elasmo[species_df_no_elasmo == 0] <- NA

# and remove rows with NAs in abundance  (this is so they don't appear as small dots in plot)
species_df_no_elasmo <-  filter(species_df_no_elasmo, !is.na(Abundance))
```



Plot by species, scientific name
```{r}
speciesbubbleplot_eDNA_sciname_no_elasmo <- ggplot(species_df_no_elasmo, aes(x = Station, y = fct_rev(species), color = Station)) + # the fancy stuff around y (species) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size = Abundance, fill = Station), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(0,.25,.5,.75,1), max_size = 6)+
  xlab("")+
  ylab("")+
  labs(size="Relative Abundance")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(Datecode~Bayside, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_eDNA_sciname_no_elasmo
```



Plot by species common name
```{r}
speciesbubbleplot_eDNA_comname_no_elasmo <- ggplot(species_df_no_elasmo, aes(x = Station, y = fct_rev(CommonName), color = Station)) + # the fancy stuff around y (CommonName) helps to present it in reverse order in the plot (from top to btm alphabetically)
  geom_point(aes(size = Abundance, fill = Station), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(0,.25,.5,.75,1), max_size = 6)+
  xlab("")+
  ylab("")+
  labs(size="Relative Abundance")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(Datecode~Bayside, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_eDNA_comname_no_elasmo
```


Exportfigures
```{r}
ggsave(filename = "Figures/speciesbubbleplot_eDNA_sciname_no_elasmo.eps", plot = speciesbubbleplot_eDNA_sciname_no_elasmo, units = c("in"), width = 7, height = 12, dpi = 300)

ggsave(filename = "Figures/speciesbubbleplot_eDNA_comname_no_elasmo.eps", plot = speciesbubbleplot_eDNA_comname_no_elasmo, units = c("in"), width = 7, height = 12, dpi = 300)
```



#  Import and prepare the data from trawls 

## Import Trawl Count Data
```{r}
# import 4th sheet from  Excel file which contains morphometric data for each individual collected for every date
trawl_master <- read_excel("Trawls MASTER 2020 _mod_ES.xlsx",4)

# and import 6th sheet which is station info
stations <- read_excel("Trawls MASTER 2020 _mod_ES.xlsx",6)

# and import shedding factor- an index determined by Sara that indicates how much the species sheds when handled (and therefore how likely it is to shed cells in water)
sheddingfactor <- read_excel("Allometric correction_mod.xlsx",5)

# Group station name and shedding factor into trawl_master table
trawl_master <- left_join(trawl_master, stations, by = "STATION_NO")
trawl_master <- left_join(trawl_master, sheddingfactor, by = "COMMONNAME")

trawl_master
```

Import station/ trawl information
```{r}
station_data <- read_excel("Trawls MASTER 2020 _mod_ES.xlsx",1)
station_data

# Filter to only include DATECODE, Station_NO, Trawl_Min
station_data <- station_data %>% select(DATECODE, STATION_NO, Trawl_Min)
station_data
```

Combine station information to trawl_master in order to have the duration of each trawl (for calculating CPUE)
```{r}
trawl_master <- left_join(trawl_master, station_data, by = c("DATECODE", "STATION_NO"))
trawl_master
```




Make an equivalent to an OTU table, grouping by date and location and representing counts for every unique species, summing the total length for each trawl/ species (in order to do allometric correction later)
```{r}
trawl_counts <- trawl_master %>%
  group_by(DATECODE, STATION_NA, STATION_NO, Trawl_Min, BAYSIDE, CommonName, SheddingFactor) %>%
  summarize(TotalLength = sum(TL_CM))


counts <- trawl_master %>%
  group_by(DATECODE, STATION_NA, STATION_NO, CommonName) %>%
  tally(name = "count")

trawl_counts <- left_join(trawl_counts, counts, by = c ("DATECODE", "STATION_NA", "STATION_NO", "CommonName"))
trawl_counts
```


Calculate CPUE and put in new column. CPUE is the count divided by trawl time (in minutes)
```{r}
trawl_counts <- trawl_counts %>%
  mutate (CPUE = count / Trawl_Min)
trawl_counts
```

Calculate the metric that Sara came up with: sum(total length) * shedding factor. This takes into account the sums of length of each fish for each date/trawl and multiplies by a factor determined by how much they shed
```{r}
trawl_counts <- trawl_counts %>%
  mutate (AllometricSheddingCPUE = TotalLength*SheddingFactor)
trawl_counts
```


Remove 09/16/20 since there is no equivalent eDNA from that date. Also remove station 13 since no equivalent eDNA samples were collected there
```{r}
trawl_counts <- trawl_counts %>%
  filter(DATECODE != "20200916")

trawl_counts <- trawl_counts %>%
  filter(STATION_NO != "13")
```



# Abundance plots Trawls

## Bubble plots of Counts

```{r}
speciesbubbleplot_trawl_comname <- ggplot(trawl_counts, aes(x = STATION_NA, y = fct_rev(CommonName), color = STATION_NA)) + 
  geom_point(aes(size = log10(count), fill = STATION_NA), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(log10(1), log10(2), log10(5), log10(10), log10(25), log10(100)), max_size = 6, labels = c("1","2","5","10","25","100"))+
  xlab("")+
  ylab("")+
  labs(size="Abundance", fill = "Station")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(DATECODE~BAYSIDE, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_trawl_comname

```

Export figure
```{r}
ggsave(filename = "Figures/speciesbubbleplot_trawl_abundance_comname.eps", plot = speciesbubbleplot_trawl_comname, units = c("in"), width = 6.75, height = 13, dpi = 300)
```





## Bubble plots of CPUE

```{r}
speciesbubbleplot_trawl_CPUE_comname <- ggplot(trawl_counts, aes(x = STATION_NA, y = fct_rev(CommonName), color = STATION_NA)) + 
  geom_point(aes(size = log10(CPUE), fill = STATION_NA), color = "black", pch = 21)+
  scale_size(range = c(1,15)) +
  scale_size_area(breaks = c(log10(1), log10(2), log10(5), log10(10), log10(25), log10(100)), max_size = 6, labels = c("1","2","5","10","25","100"))+
  xlab("")+
  ylab("")+
  labs(size="CPUE", fill = "Station")+
  theme_bw() +
  scale_fill_brewer(palette="Paired") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  facet_grid(DATECODE~BAYSIDE, scales = "free", space = "free", drop= TRUE)

speciesbubbleplot_trawl_CPUE_comname
```
Looks good! Similar to "counts" figure but some adjustments that normalized for trawling time.


Export figure
```{r}
ggsave(filename = "Figures/speciesbubbleplot_trawl_CPUE_comname.eps", plot = speciesbubbleplot_trawl_CPUE_comname, units = c("in"), width = 6.75, height = 13, dpi = 300)
```


# Compare Trawl and eDNA

## Prepare the data
First, remove the species from the trawls that are not targeted in the eDNA assay (invertebrates and elasmobranchs)
```{r}
# import a list of the "OK" species that are targetted by MiFISh primers
mifish_spp <- read_excel("Trawl CPUE no elasmobranch_mod.xlsx",2)

# filter rows from trawl_counts if the spp name doesn't match the MiFISh list
trawl_counts <- right_join(trawl_counts, mifish_spp, by = "CommonName")
trawl_counts
```

Then filter out stations from trawl data that were removed samples from eDNA analysis because of poor sequencing effort.
Filtered eDNA samples: 
T1S7 (20200707, CORMORANT POINT)
T1S8 (20200707, SHINNECOCK HILLS)
T3S11 (20200805, LITTLE POND)
T1S2 (20200707, WEST MID BAY)
T4S5 (20200819, PONQUOGUE BRIDGE)

```{r}
trawl_counts <- trawl_counts %>%
  filter(!DATECODE == "20200707" | !STATION_NA == "CORMORANT POINT") %>%
  filter(!DATECODE == "20200707" | !STATION_NA == "SHINNECOCK HILLS") %>%
  filter(!DATECODE == "20200805" | !STATION_NA == "LITTLE POND") %>%
  filter(!DATECODE == "20200707" | !STATION_NA == "WEST MID BAY") %>%
  filter(!DATECODE == "20200819" | !STATION_NA == "PONQUOGUE BRIDGE")

trawl_counts

# sum hits across all dates in trawl
trawl_uniques <- trawl_counts %>%
  group_by(DATECODE, CommonName) %>%
  summarise(Trawl_Count = sum(count, na.rm=TRUE), Trawl_CPUE = sum(CPUE, na.rm = TRUE), Trawl_TL = sum(TotalLength, na.rm = TRUE), Trawl_Allometric_Shedding = sum(AllometricSheddingCPUE, na.rm = TRUE))
trawl_uniques

# sum hits across all dates in eDNA
eDNA_uniques <- species_df_no_elasmo%>%
  group_by(Datecode, CommonName) %>%
  summarise(eDNA_RelAbun = sum(Abundance, na.rm=TRUE))
eDNA_uniques

# Combine into one dataframe
trawl_eDNA_abun_table <- full_join(trawl_uniques, eDNA_uniques, by=c("CommonName" = "CommonName", "DATECODE" = "Datecode"))

trawl_eDNA_abun_table
```


## Species Richness
Count unique species across all stations, grouped by date, for each method, trawl& eDNA (use filtered trawl data so only comparing MiFISh spp to MiFISh spp).

Count total number of species from each method for each date
```{r}
eDNA_richness <- tally(eDNA_uniques, name = "eDNA")
trawl_richness <- tally(trawl_uniques, name = "trawl")

speciesrichness <- full_join(eDNA_richness, trawl_richness, c("Datecode" = "DATECODE"))
speciesrichness <- pivot_longer(speciesrichness, !Datecode, names_to = "Method", values_to = "Richness")

speciesrichness$Datecode <- ymd(speciesrichness$Datecode) # convert to date format (better for plotting)

speciesrichness
```


Plot side-by-side
```{r}
species_richness_plot <- ggplot(speciesrichness, aes(x =Datecode, y = Richness)) +
  geom_line(aes(color = Method), size = 3) +
  theme_bw() +
  xlab("") +
  ylab("Species Richness")

species_richness_plot

# export plot
ggsave(filename = "Figures/species_richness_plot.eps", plot = species_richness_plot, units = c("in"), width = 4, height = 3, dpi = 300)
```



Sum total number of species across all dates/ stations for entire study
```{r}
species_sums_abun_table <- trawl_eDNA_abun_table %>%
  group_by(CommonName) %>%
  summarise(CPUE = sum(Trawl_CPUE, na.rm = TRUE), 
            "Total Length (TL)" = sum(Trawl_TL, na.rm = TRUE), 
            "TL * Shedding Factor" = sum(Trawl_Allometric_Shedding, na.rm = TRUE), 
            eDNA = sum(eDNA_RelAbun, na.rm=TRUE)) %>%
  pivot_longer(!CommonName, names_to = "Method", values_to = "Abundance")
  
# turn zeroes to NA so they don't plot 
species_sums_abun_table <- na_if(species_sums_abun_table,0)

species_sums_abun_table
```

## Species tally across whole study

For each species, plot side-by-side comparison of abundance (summed over whole study) using each method

```{r}
# First create a custom color scale to make this pretty
myColors <- colorRampPalette(brewer.pal(11,"Spectral"))(40)
names(myColors) <- levels(unique(species_sums_abun_table$CommonName))
colScale <- scale_colour_manual(name = "CommonName",values = myColors)

species_abun_sum_plot <- ggplot(species_sums_abun_table, aes(x = Abundance, y = reorder(CommonName, Abundance, function(x){sum(x,na.rm = TRUE)}), color = CommonName)) +
  geom_point(size = 5) +
  facet_wrap(~factor(Method, levels = c('CPUE','Total Length (TL)','TL * Shedding Factor','eDNA')), scales = "free_x", ncol = 4) +
  theme_bw() +
  xlab("Abundance") +
  ylab("") + 
  colScale +
  theme(legend.position = "none")

species_abun_sum_plot
```

Export plot
```{r}
ggsave(filename = "Figures/species_abun_sum_plot.eps", plot = species_abun_sum_plot, units = c("in"), width = 10, height = 6, dpi = 300)
```




# Exploratory Analyses

## Ordinations on eDNA

I will try PCoA, PCA (the Euclidean PCoA) and NMDS ordinations in combination with different tranformations and distance metrics in order to see which explain the most variance in the dataset.

- NOTE- see this [discussion](https://stats.stackexchange.com/questions/305965/can-i-use-the-clr-centered-log-ratio-transformation-to-prepare-data-for-pca) and this [paper](https://link.springer.com/article/10.1007/s11004-008-9196-y) on why CCA should not be used with CLR-transformed compositional data to explore correlations.

### PCA
PCA is essentially a type of PCoA  using the Euclidean distance matrix as input. When combined with a log-ratio transformation of the count table, this is deemed appropriate for *compositional* datasets. It is also [recommended](https://sites.google.com/site/mb3gustame/indirect-gradient-analysis/pca) as a first step in exploratory analyses of sequencinging datasets.

First do a **CLR, centered log ratio** transformation of the absolute abundance data (after filtering), as suggested by [Gloor et al. 2017](https://www.frontiersin.org/articles/10.3389/fmicb.2017.02224/full)  
```{r}
# Estimate covariance matrix for CLR-transformed ASV table
clr_asv_table_ps <- data.frame(compositions::clr(otu_table(ps_no_elasmo)))
```


Generate the PCA and visualize axes
```{r}
# Generate a Principle Component Analysis (PCA) and evaluated based on the eigen decomposition from sample covariance matrix. 
lograt_pca <- prcomp(clr_asv_table_ps) 
# NOTE- this is equivalent to first making a Euclidean distance matrix using the CLR data table and then running a PCoA. A Euclidean distance matrix of a log-transformed data table = an Aitchison distance matrix. So this is equivalent to the compositional methods listed in Gloor et al.

# Visual representation with a screeplot
lograt_variances <- as.data.frame(lograt_pca$sdev^2/sum(lograt_pca$sdev^2)) %>% #Extract axes
  # Format to plot
  select(PercVar = 'lograt_pca$sdev^2/sum(lograt_pca$sdev^2)') %>% 
  rownames_to_column(var = "PCaxis") %>% 
  data.frame
head(lograt_variances)

# Plot screeplot
ggplot(lograt_variances, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Log-Ratio PCA Screeplot, CLR Tranformation")
```

Total variance explained by first three axes= 15.8 + 10.7 + 10.1 = **36.6%**. Since the second and third axes are similar, plot in 3D with 3 axes.

Visualize the PCA- 

```{r}
# Extract variances from the clr pca
pca_lograt_frame <- data.frame(lograt_pca$x) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
pca_lograt_frame <- left_join(pca_lograt_frame, metadata, by = "SampleID")
head(pca_lograt_frame)

# Select eigenvalues from dataframe, round to 4 places and multiply by 100 for plotting. These will be the axes for the 3-D plot
eigenvalues<-round(lograt_variances[,2], digits = 4)*100

# Plotly - 3-D
pca_lograt <- plot_ly(pca_lograt_frame, type='scatter3d', mode='markers',
        x=~PC1,y=~PC2,z=~PC3,colors=~brewer.pal(11,'Paired'),
        color=~Station, symbols = c('circle','diamond'), symbol=~Bayside)%>%
  layout(font=list(size=12),
         title='CLR-Euclidean PCA',
         scene=list(xaxis=list(title=paste0('Co 2 ',eigenvalues[2],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    yaxis=list(title=paste0('Co 3 ',eigenvalues[3],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    zaxis=list(title=paste0('Co 1 ',eigenvalues[1],'%'),
                               showticklabels=FALSE,zerolinecolor='black')))
# pca_lograt

# save in "Embedded_figures" directory so that it can be hosted at Github and embedded in this notebook
withr::with_dir('Embedded_figures', htmlwidgets::saveWidget(as_widget(pca_lograt), file="pca_lograt.html", selfcontained = F))

 
```


<iframe src="Embedded_figures/pca_lograt.html" height="600px" width="100%" style="border:none;"></iframe>

**Summary** The CLR-Euclidean PCA reveals there is some separation according to East vs West. The PCA only explains ~36% of the variance so keep going with different ordinations to see if there is a better representation



### PCoA Jaccard
The more traditional approach to ordinations is to do a PCoA on a distance matrix such as Bray-Curtis, Jaccard, or Unifrac. When combined with a transformation, they become more appropriate for NGS data. One such common transformation is the Hellinger transformation.

The different distance matrices also tell you a few different things about the dataset so I will run try different one to try to see if I can tease those out. 

Before calculating any distance matrix, do a transformation of the filtered count table. Hellinger transformation is the square root of the relative abundance, so calculate it based on the ps_ra object:

```{r}
ps_hellinger <- transform_sample_counts(ps_ra_no_elasmo, function(x){sqrt(x)})
```


First, **Jaccard**, which builds the distance matrix based on presence/absence between samples. It does not take into account relative abundance of the taxa. Therefore this functions well for determining differences driven by rare taxa, which are weighed the same as abundant taxa.
```{r}
jac_dmat<-vegdist(otu_table(ps_hellinger),method="jaccard") # Jaccard dist metric
pcoa_jac<-ape::pcoa(jac_dmat) # perform PCoA

# Extract variances from pcoa, from jaccard calculated dist. metric
jac_variances <- data.frame(pcoa_jac$values$Relative_eig) %>% 
  select(PercVar = 'pcoa_jac.values.Relative_eig') %>% 
  rownames_to_column(var = "PCaxis") %>% 
  data.frame
head(jac_variances)

# Make a screeplot
ggplot(jac_variances, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Jaccard PCoA Screeplot")
```
The first two axes (19.0 + 9.7 = 28.7) are OK. But plot the first 3 axes since the 2nd and 3rd explain a similar amount of variance, (19.0 + 9.7 + 8.4 = **37.1%** total variance explained) 

Plot in 3D with Plotly
```{r}
# Extract variances from the jaccard pcoa
pcoa_jac_df <- data.frame(pcoa_jac$vectors) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
pcoa_jac_df <- left_join(pcoa_jac_df, metadata, by = "SampleID")
head(pcoa_jac_df)

# Select eigenvalues from dataframe, round to 4 places and multiply by 100 for plotting. These will be the axes for the 3-D plot
eigenvalues<-round(jac_variances[,2], digits = 4)*100

# Plotly - 3-D
pcoa_jaccard <- plot_ly(pcoa_jac_df, type='scatter3d', mode='markers',
        x=~Axis.2,y=~Axis.3,z=~Axis.1,colors=~brewer.pal(11,'Paired'),
        color=~Station, symbols = c('circle','diamond'), symbol=~Bayside)%>%
  layout(font=list(size=12),
         title='PCoA Jaccard Distance',
         scene=list(xaxis=list(title=paste0('Co 2 ',eigenvalues[2],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    yaxis=list(title=paste0('Co 3 ',eigenvalues[3],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    zaxis=list(title=paste0('Co 1 ',eigenvalues[1],'%'),
                               showticklabels=FALSE,zerolinecolor='black')))
# pcoa_jaccard

# save figure in "Embedded_figures" directory so that it can be hosted at Github and embedded in this notebook
withr::with_dir('Embedded_figures', htmlwidgets::saveWidget(as_widget(pcoa_jaccard), file="pcoa_jaccard.html", selfcontained = F))
```

<iframe src="Embedded_figures/pcoa_jaccard.html" height="600px" width="100%" style="border:none;"></iframe>

The Jaccard-PCoA shows some separation along axis 2 and axis 3 in East vs West differences. Very similar % variance explained to the PCA.


### PCoA Bray Curtis

Next, try a **Bray-Curtis** distance matrix with PCoA, which builds the distance matrix based on presence/absence between samples *and* relative abundance differences. This ordination will represent well the differences in samples that are driven by taxa with high relative abundances.

NOTE: I need to use a correction here for negative eigenvalues. Read more [here](https://fromthebottomoftheheap.net/slides/intro-vegan-webinar-2020/intro-to-vegan.html#53)
```{r}
bray_dmat<-vegdist(otu_table(ps_hellinger),method="bray") # Bray-Curtis dist metric
pcoa_bray<-ape::pcoa(bray_dmat) # perform PCoA in ape. But getting negative eigenvalues, so need to add correction. wcmdscale from base R also performs PCoA and can add cailliez correction
pcoa_bray <- wcmdscale(bray_dmat, eig = TRUE, add = "cailliez")

# check out summary of PCoA
eigenvals(pcoa_bray) %>%
  summary() -> ev
ev

# extract variances and put in tibble
bray_variances <- NULL
for (i in 1:length(eigenvals(pcoa_bray))){
  bray_variances[i] <- eigenvals(pcoa_bray)[i]/sum(eigenvals(pcoa_bray))
}

# Extract variances from pcoa, from calculated dist. metric
bray_variances <- tibble(round(bray_variances,3)) %>%
  select(PercVar = 'round(bray_variances, 3)') %>%
  rownames_to_column(var = "PCaxis") %>%
  data.frame
head(bray_variances)

# Make a screeplot
ggplot(bray_variances, aes(x = as.numeric(PCaxis), y = PercVar)) + 
  geom_bar(stat = "identity", fill = "grey", color = "black") +
  theme_minimal() +
  theme(axis.title = element_text(color = "black", face = "bold", size = 10),
        axis.text.y = element_text(color = "black", face = "bold"),
        axis.text.x = element_blank()) +
  labs(x = "PC axis", y = "% Variance", title = "Bray-Curtis PCoA Screeplot")
```
The first two axes (21.1 + 11.0) are pretty good again but I am still going to experiment in the plot with the 3rd axis since it is similar to the second (9.5%; total variance explained = **41.6%**)




Plot in 3D with Plotly
```{r}
# Extract variances from the pcoa
pcoa_bray_df <- data.frame(pcoa_bray$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
pcoa_bray_df <- left_join(pcoa_bray_df, metadata, by = "SampleID")
head(pcoa_bray_df)

# Select eigenvalues from dataframe, round to 4 places and multiply by 100 for plotting. These will be the axes for the 3-D plot
eigenvalues<-round(bray_variances[,2], digits = 4)*100

# Plotly - 3-D
pcoa_bray <- plot_ly(pcoa_bray_df, type='scatter3d', mode='markers', 
                     x=~Dim2, y=~Dim3, z=~Dim1, colors=~brewer.pal(11,'Paired'),
        color=~Station, symbols = c('circle','diamond'), symbol=~Bayside)%>%  
  layout(font=list(size=12),
         title='PCoA Bray-Curtis Distance',
         scene=list(xaxis=list(title=paste0('Co 2 ',eigenvalues[2],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    yaxis=list(title=paste0('Co 3 ',eigenvalues[3],'%'),
                               showticklabels=FALSE,zerolinecolor='black'),
                    zaxis=list(title=paste0('Co 1 ',eigenvalues[1],'%'),
                               showticklabels=FALSE,zerolinecolor='black')))
# pcoa_bray

# save in "Embedded_figures" directory so that it can be hosted at Github and embedded in this notebook
withr::with_dir('Embedded_figures', htmlwidgets::saveWidget(as_widget(pcoa_bray), file="pcoa_bray.html", selfcontained = F))
```

<iframe src="Embedded_figures/pcoa_bray.html" height="600px" width="100%" style="border:none;"></iframe>


These results along axes 1, 2, and 3 are similar to Jaccard, but there is MORE separation along axis 2, indicating that incorporating the differences in abundance helps explain more variance in the dataset. Total variance explained is highest so far.




### NMDS Aitchison
Lastly, try a non-metric dimensional scaling ordination. PCA/PCoA are metric and attempt to rotate axes to fit the distance matrix distribution. An NMDS represents the data in 2-axes, by constraining the distribution of the points. Similar to above, this can be combined with different pre-treatment of the data.

First try the compositional approach, an **NMDS on CLR-tranformed data using the Euclidean distances** (aka Aitchison distance)

```{r}
euc_dmat<-dist(clr_asv_table_ps, method = "euclidean") # Build the Aitchison distance matrix
euc_nmds <- metaMDS(euc_dmat, k=2, autotransform=FALSE) # Run the ordination
euc_nmds$stress #Check the stress. Less than 0.1 is good. Less than 0.05 is better. This will be different each time, since it is iteratively finding a unique solution each time (although the should look similar)

# Extract points from nmds and merge into data frame with metadata 
euc_nmds_df <- data.frame(euc_nmds$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
euc_nmds_df <- left_join(euc_nmds_df, metadata, by = "SampleID")
head(euc_nmds_df)



## Plotting euclidean distance NMDS
nmds_aitch <- ggplot(euc_nmds_df,aes(x = MDS1, y = MDS2, color = Station, shape = Bayside)) +
  geom_point(size = 4) +
  scale_color_brewer(palette="Paired") +
  theme_bw() +
  labs(x = "NMDS 1", y = "NMDS 2", title = paste0('Aitchison Distance NMDS, Stress = ', round(euc_nmds$stress,2))) +
  coord_fixed(ratio = 1)

nmds_aitch

ggsave("figures/nmds_aitch.eps",nmds_aitch, width = 7, height = 5, units = c("in"))
```
The above has a relatively **high stress (>0.2)** so should be interpreted with caution. But it does show some separation East vs West along NMDS 1.

### NMDS Jacaard


Next try a **Jaccard NMDS**, which will represent differences in presence/absence among samples, emphasizing both abundant and rare taxa the same

```{r}
jac_nmds <- metaMDS(jac_dmat, k=2, autotransform=FALSE) # Run the ordination. Distance matrix was already calculated above
jac_nmds$stress #Check the stress. Less than 0.1 is good. Less than 0.5 is better. This will be different each time, since it is iteratively finding a unique solution each time (although the should look similar)

# Extract points from nmds and merge into data frame with metadata 
jac_nmds_df <- data.frame(jac_nmds$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
jac_nmds_df <- left_join(jac_nmds_df, metadata, by = "SampleID")
head(jac_nmds_df)



## Plotting euclidean distance NMDS
nmds_jaccard <- ggplot(jac_nmds_df,aes(x = MDS1, y = MDS2, color = Station, shape = Bayside)) +
  geom_point(size = 4) +
  scale_color_brewer(palette="Paired") +
  theme_bw() +
  labs(x = "NMDS 1", y = "NMDS 2", title = paste0('Jaccard Distance NMDS, Stress = ', round(jac_nmds$stress,2))) +
  coord_fixed(ratio = 1)

nmds_jaccard

ggsave("figures/nmds_jaccard.eps",nmds_jaccard, width = 7, height = 5, units = c("in"))
```
This is still a **moderately high stress (>0.1)** so should be interpreted with caution. Similar to Aitchison-distance nMDS but there is a little more separation of East vs West on NMDS 2 axis.

### NMDS Bray Curtis

Next try a **Bray-Curis NMDS**, which will represent differences in presence/absence among samples *and* relative abundance, thus emphasizing impacts of highly abundant taxa.

```{r}
bray_nmds <- metaMDS(bray_dmat, k=2, autotransform=FALSE) # Run the ordination. Distance matrix was already calculated above
bray_nmds$stress #Check the stress. Less than 0.1 is good. Less than 0.5 is better. This will be different each time, since it is iteratively finding a unique solution each time (although the should look similar)

# Extract points from nmds and merge into data frame with metadata 
bray_nmds_df <- data.frame(bray_nmds$points) %>% 
  rownames_to_column(var = "SampleID")

# Merge metadata into the pcoa data table
bray_nmds_df <- left_join(bray_nmds_df, metadata, by = "SampleID")
head(bray_nmds_df)



## Plotting euclidean distance NMDS
nmds_bray <- ggplot(bray_nmds_df,aes(x = MDS1, y = MDS2, color = Station, shape = Bayside)) +
  geom_point(size = 4) +
  scale_color_brewer(palette="Paired") +
  theme_bw() +
  labs(x = "NMDS 1", y = "NMDS 2", title = paste0('Bray-Curtis Distance NMDS, Stress = ', round(bray_nmds$stress,2))) +
  coord_fixed(ratio = 1)

nmds_bray

ggsave("figures/nmds_bray.eps",nmds_bray, width = 7, height = 5, units = c("in"))
```
Very similar to Jaccard results. **Moderately high stress (0.15)**


### eDNA Ordinations Summary
The ordination that explained the most variance in the eDNA dataset was the PCoA using the Bray-Curtis dissimilarity matrix after Hellinger transformation. This is similar to the approach presented in [Lacoursière‐Roussel et al. 2018](https://onlinelibrary.wiley.com/doi/abs/10.1002/ece3.4213). Use this representation going forward.

- Next: fit environmental vectors to this ordination to see which can be possibly explain some of the variation among samples and among species.

## PCoA with Environmental Variables

Recreate, in 2D, the first two axes of the ordination (PCoA with Bray distance matrx/ Hellinger transformation) and use `envfit` from vegan to test and fit environmental variables.

If not making 3D plots, can do this directly in phyloseq ( [example](https://www.gdc-docs.ethz.ch/MDA/handouts/MDA20_PhyloseqFormation_Mahendra_Mariadassou.pdf) ). But phyloseq doesn't allow for calliez correction of PCoA, so instead use example from [G. Simpson](https://fromthebottomoftheheap.net/slides/intro-vegan-webinar-2020/intro-to-vegan.html#1) to fit envfit on top of output from wcmdscale (PCoA in vegan).

Prepare the ordination variables
```{r}
pcoa_bray <- wcmdscale(bray_dmat, eig = TRUE, add = "cailliez")

# trim metadata to remove samples that were removed during QC
metadata_ordinations <- metadata[metadata$SampleID %in% sample_data(ps_hellinger)$SampleID,]

# and remove repetitive metadata variables like Date/ Month/ Year/ Trawl #
metadata_ordinations <- select(metadata_ordinations, -"Year.Trawl#", -Date, -Month, -Year)

# sort metadata in same order as the distance matrix, bray_dmat
metadata_ordinations <- metadata_ordinations %>% arrange(factor(SampleID, levels = rownames(otu_table(ps_hellinger))))

# change the column name "Datecode" to "Date" (better for plotting)
colnames(metadata_ordinations)[2] <- "Date"

# fit environmental factors and save stats output
pcoa_bray_envfit <- envfit(pcoa_bray, metadata_ordinations, permutations = 1000)
capture.output(pcoa_bray_envfit, file = "stats_results/pcoa_bray_envfit.txt")

# Signficant variables include Datecode (p = 0.023976), DO (p = 0.000999), Bayside (p = 0.004995), and Station (p = 0.041958)

# Make each of the interesting variables their own ordination variables for plotting (exclude Station. This will be a color variable anyway and it's not interesting)
pcoa_bray_envfit_date <- envfit(pcoa_bray~Date, metadata_ordinations, permutations = 1000)
pcoa_bray_envfit_DO <- envfit(pcoa_bray~DO, metadata_ordinations, permutations = 1000)
pcoa_bray_envfit_Bayside <- envfit(pcoa_bray~Bayside, metadata_ordinations, permutations = 1000)

```


Plot
```{r}
# Convert characters in metadata to factors
metadata_ordinations <- metadata_ordinations %>% mutate_if(sapply(metadata_ordinations, is.character), as.factor)
with(as.data.frame(metadata_ordinations), levels(Station))

# Define plot parameters
colvec <- c(brewer.pal(11,'Paired')) # colors of stations
shapevec <- c(19,18) # shapes indicating Bayside

# Set up basic plot
par(xpd = T, mar = par()$mar + c(0,0,0,8)) # leave space to add legend. xpd = T allows legend to be outside of the plot
# Add the site scores
with(metadata_ordinations, plot(scores(pcoa_bray, display = "sites"), col = colvec[Station], pch = shapevec[Bayside], cex = 2, xlab = "Co1 21.1%", ylab = "Co2 11.0%"))
# Add the date vector
plot(pcoa_bray_envfit_date, p.max = 0.1, lwd = 2, col = "black")
# Add the DO vector
plot(pcoa_bray_envfit_DO, p.max = 0.1, lwd = 2, col = "black")
# Add the hulls indicating Bayside
with(metadata_ordinations, ordihull(pcoa_bray, Bayside, lwd = 2, lty = c(3,5), label = FALSE))
# Add legends
with(metadata_ordinations, legend(0.77, 0.6, legend = levels(Station), col = colvec, pch = c(19,18,19,19,19,18,19,19,19,18,18), bty = "n", pt.cex = 2, cex = .8))
legend(0.77, 0.8, c("EAST", "WEST"), col = c("black"), lty = c(3,5), lwd = 2, bty = "n", cex = .8) # Legend for Bayside hull lines- did this manually


# Export using base R/ vegan helpers
setEPS()
postscript("Figures/pcoa_bray_envfit.eps", width = 7, height = 5)
par(xpd = T, mar = par()$mar + c(0,0,0,8))
with(metadata_ordinations, plot(scores(pcoa_bray, display = "sites"), col = colvec[Station], pch = shapevec[Bayside], cex = 2, xlab = "Co1 21.1%", ylab = "Co2 11.0%"))
plot(pcoa_bray_envfit_date, p.max = 0.1, lwd = 2, col = "black")
plot(pcoa_bray_envfit_DO, p.max = 0.1, lwd = 2, col = "black")
with(metadata_ordinations, ordihull(pcoa_bray, Bayside, lwd = 2, lty = c(3,5), label = FALSE))
with(metadata_ordinations, legend(0.77, 0.6, legend = levels(Station), col = colvec, pch = c(19,18,19,19,19,18,19,19,19,18,18), bty = "n", pt.cex = 2, cex = .8))
legend(0.77, 0.8, c("EAST", "WEST"), col = c("black"), lty = c(3,5), lwd = 2, bty = "n", cex = .8) 
dev.off()

```



## Ordinations on CPUE

Does CPUE data need to be transformed before ordinations?

- [Sabel et al. 2020](https://onlinelibrary.wiley.com/doi/full/10.1111/fwb.13501) do a log-transformation, then center and standardize counts before PCA
- [Gothues and Able 2020](https://onlinelibrary.wiley.com/doi/full/10.1111/rec.13163?casa_token=UeUAUp99yecAAAAA%3AXuJGz6ailZDq5BW27vlrRudui96Dcv-jGjAOV0USSAYpiFbr3oM7Y1GQgblJjO4n1VhqhdhgeC9vt8E) also log transform ( log(y+1) ) and center and standardize to units of standard deviation before PCA. They also excluded rare species (less than 3 occurences at all sites)
- [Wegsheider et al. 2020](https://onlinelibrary.wiley.com/doi/full/10.1002/rra.3615?casa_token=-EV_HEpQ3sgAAAAA%3ALqeKBsNjFyz6t4KVrgFrelKTOj_mAjaVCLx-fo07yVdp_n_R0pKMr4u2G7Enqgu-Dd1Etl9lkc5I2KU) do no transformation, as far as I can tell, before PCoA
- [Mehdi et al. 2021](https://www.sciencedirect.com/science/article/pii/S0048969720369618?casa_token=RiOhMzLOKkoAAAAA:uq-0S9llQLsAHA22HlIXL_6JRPgePwzvGzkF2xGzXwG-BM5pcyC9CuY9Vwa7IZG9Twb-XQWTYw#f0015) use a PCoA without transformation but with a Bray-Curtis dissimilarity matrix



## CONTINUE HERE. TRAWL_COUNTS IS READY TO GO WITH ALL ALLOMETRIC CORRECTED DATA

